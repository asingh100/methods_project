---
title: "Data Exploration"
author: "Hanfei Qi, Anmol Singh, Wuraola Olawole, Ting Lian"
date: "12/4/2020"
output: github_document
---

### Data Exploration:

```{r setup, include = FALSE, message = FALSE}
library(tidyverse)
library(arsenal)
library(HH)
library(MASS)
library(zoo)
library(interactions)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

Read data and make sure factors are factors.

```{r, message=FALSE, warning=FALSE}
crime_df = 
  read_csv("data/HateCrimes.csv") %>% 
  mutate(
    unemployment = factor(unemployment),
    urbanization = factor(urbanization),
    hate_crimes_per_100k_splc = as.numeric(hate_crimes_per_100k_splc)
  )
```

Descriptive statistics

```{r}
my_controls =  tableby.control(
               total = F,
               test=F,  
               numeric.stats = c("meansd", "medianq1q3", "range", "Nmiss2"),
               cat.stats = c("countpct", "Nmiss2"),
               stats.labels = list(
               meansd = "Mean (SD)",
               medianq1q3 = "Median (Q1, Q3)",
               range = "Min - Max",
               Nmiss2 = "Missing",
               countpct = "N (%)"))

tab = tableby( ~ hate_crimes_per_100k_splc + unemployment + urbanization + median_household_income +   perc_population_with_high_school_degree + perc_non_citizen + gini_index + perc_non_white, 
               data = crime_df, 
               control = my_controls)

summary(tab, title = "Descriptive Statistics: Hate Crime Data", text = T)
```

Comment: there are 4 NA's in variable `hate_crimes_per_100k_splc` and 3 NA's in variable `perc_non_citizen`.  


Code to remove NA's (not sure if we wanna do that).
```{r, message=FALSE, warning=FALSE}
crime_df_no_na = 
  read_csv("data/HateCrimes.csv", na = c("", "N/A")) %>% 
  mutate(
    unemployment = factor(unemployment),
    urbanization = factor(urbanization),
    hate_crimes_per_100k_splc = as.numeric(hate_crimes_per_100k_splc)
  ) %>% 
  na.omit()
```

Distribution of the outcome
```{r}
crime_df_no_na %>% 
  ggplot(aes(x = hate_crimes_per_100k_splc)) + geom_density()
```

Comment: we need transformation

```{r}
mod = 
  lm(hate_crimes_per_100k_splc ~ unemployment + urbanization + median_household_income +   perc_population_with_high_school_degree + perc_non_citizen + gini_index + perc_non_white, 
      data = crime_df_no_na)

boxcox(mod)
```

Perform the tranformation.
```{r}
trans_df = 
  crime_df_no_na %>% 
  mutate(
    hate_crimes_per_100k_splc = log(hate_crimes_per_100k_splc)
  )

trans_df %>% 
  ggplot(aes(x = hate_crimes_per_100k_splc)) + geom_density()
```

Looks good!

Plots before and after transformation.
```{r}
plot(mod)
```

```{r}
mod_trans = lm(hate_crimes_per_100k_splc ~ unemployment + urbanization + median_household_income +   perc_population_with_high_school_degree + perc_non_citizen + gini_index + perc_non_white, 
      data = trans_df)

plot(mod_trans)
```


Plot crime rate by states.
```{r}
crime_df_no_na %>% 
  mutate(state = fct_reorder(state, hate_crimes_per_100k_splc)) %>% 
  ggplot(aes(x = state, y = hate_crimes_per_100k_splc)) + 
  geom_point() + 
  geom_line() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

Comment: A wired point in `District of Columbia`. The rate of `Oregon` is slightly higher than other states. I will also consider `Minnesota`, `Massachusetts`, `Washington` as potential outliers.

### Modeling:


**Test if association between income inequality and hate crimes holds true:**

```{r}
income_hate_model_full_data = crime_df%>%
  lm(hate_crimes_per_100k_splc~gini_index,data=.)

income_hate_model_full_data%>%
  broom::tidy()%>%
  knitr::kable(caption = "Testing Association between Income Inequality and Hate Crime using all the data", format = "html")

income_hate_model_trans = crime_df%>%
  mutate(
    hate_crimes_per_100k_splc = log(hate_crimes_per_100k_splc)
  )%>%
  lm(hate_crimes_per_100k_splc~gini_index,data=.)

income_hate_model_trans%>%
  broom::tidy()%>%
  knitr::kable(caption = "Testing Association between Income Inequality and Hate Crime using log transformed data", format = "html")

```


p-value is only significant for data which is not transformed or when outliers are not removed. Lets check model diagnostics to confirm though.

**Model Diagnostics:**

```{r}
#For original data:

plot(income_hate_model_full_data)
```

```{r}
#For log-transformed data

plot(income_hate_model_trans)
```

Looking at leverage plots for both models there are definite outliers, will remove and check models again.

**Confirming Outliers:**

```{r}
lower = quantile(crime_df$hate_crimes_per_100k_splc,0.25,na.rm = T)-(1.5*IQR(crime_df$hate_crimes_per_100k_splc,na.rm=T)) #determining lower bound for outlier
upper = quantile(crime_df$hate_crimes_per_100k_splc,0.75, na.rm=T)+(1.5*IQR(crime_df$hate_crimes_per_100k_splc,na.rm=T)) #determining upper bound for outlier
outliers = crime_df$state[(crime_df$hate_crimes_per_100k_splc>upper |crime_df$hate_crimes_per_100k_splc<lower)] #finding states that are outliers
```

**Removing Outliers:**

```{r}
crime_df_no_outlier = crime_df%>%
  filter(!state %in% outliers)
```

```{r}
#For original data without outliers:

income_hate_model_no_outlier = lm(hate_crimes_per_100k_splc~gini_index,data=crime_df_no_outlier)

plot(income_hate_model_no_outlier)
```

```{r}
#For log-transformed data with no outliers

income_hate_model_trans_no_outlier = crime_df_no_outlier%>%
  mutate(
    hate_crimes_per_100k_splc = log(hate_crimes_per_100k_splc)
  )%>%
  lm(hate_crimes_per_100k_splc~gini_index,data=.)

plot(income_hate_model_trans_no_outlier)
```

Plots are closer to model assumptions without outliers present.

**Correlation Matrix of All Variables:**

```{r}
corr_matrix = trans_df%>%
  mutate(unemployment = ifelse(unemployment=="high",1,0),
         urbanization = ifelse(urbanization=="high",1,0))%>%
  dplyr::select(-state)%>%
         cor()%>%
  data.frame()

corr_matrix%>%
  knitr::kable(caption = "Correlation Matrix for all variables except for State in Data Set", format = "html")

highly_correlated = data.frame(Correlation = corr_matrix[corr_matrix>=abs(0.6)&corr_matrix<abs(1)])

highly_correlated =  highly_correlated[!duplicated(highly_correlated),]%>%
  data.frame()%>%
  rename(Correlation = ".")%>%
  mutate(Variable_1 = c("urbanization","median_household_income","perc_non_citizen"),Variable_2 = c("perc_non_citizen","perc_population_with_high_school_degree","perc_non_white"))

highly_correlated%>%
  knitr::kable(caption = "Variables that are Highly Correlated (Correlation >= absolute value (0.6))", format = "html")

```

Studies have shown that high income is correlated with increased education and thus it would make sense that the median income and percentage of high school diploma holders are highly correlated [[1]](https://budgetmodel.wharton.upenn.edu/issues/2016/2/22/education-and-income-growth). Furthermore, a study conducted by the pew research center found that only 17.7% of immigrants are white non-hispanic which makes sense why the percentage of non citizens and the percentage of white people are very highly correlated as well [[2]](https://www.pewresearch.org/hispanic/2020/08/20/facts-on-u-s-immigrants-current-data/). Since these sets of variables are so highly correlated it would only be beneficial to adjust for one from each set in our model due to multicollinearity. 

**Stepwise Regression procedure for Removing highly-correlated predictors:**

```{r}
library(leaps)
#start with model using all predictors: 
crime_trans = crime_df_no_outlier%>%
  mutate(
    hate_crimes_per_100k_splc = log(hate_crimes_per_100k_splc)
  )%>%
  drop_na()

mod_trans = lm(hate_crimes_per_100k_splc ~ unemployment + urbanization + median_household_income +   perc_population_with_high_school_degree + perc_non_citizen + gini_index + perc_non_white,data=crime_trans)

summary(mod_trans)

#start stepwise regression procedure :

mod_tidy = mod_trans%>%
  broom::tidy()

step(mod_trans, direction='backward')

#Final Recommended Model:

final_rec = lm(formula = hate_crimes_per_100k_splc ~ unemployment + perc_population_with_high_school_degree + gini_index, data = crime_trans)

summary(final_rec)

final_rec_df = final_rec%>%broom::tidy()

#Comparing R-squared of final model vs model containing all variables:

#Final Recommendation from Stepwise Regression:

final_rec %>% broom::glance()

#Model with all variables:

mod_trans %>% broom::glance()
```

R squared is around the same for both models, however final model has 138% improvement in adjusted R squared compared to model that contains all variables. 

# Explore interactions of all variables
```{r}
crime =
  crime_trans %>%
 dplyr::select(-state)

```

Check for 2-way interactions between all predictors
```{r}
lm.fit = lm(hate_crimes_per_100k_splc ~ (.)^2, data = crime)
lm_fit_df = broom::tidy(lm.fit)
lm_fit_df

# obtain significant interactions
all_int =
  broom::tidy(lm.fit) %>%
 slice(9:29) %>%
  filter(p.value < 0.05)

all_int # these are the significant interactions present in our data

```
From the analysis above, we see 4 significant interactions: unemployment and median household income, urbanization and median household income, urbanization and perc_population with HS degree, and finally median_household income and gini index.


```{r}
# Unemployment and median household income
reg_med<-lm(hate_crimes_per_100k_splc ~ median_household_income *unemployment, data = crime)
  summary(reg_med)
    interact_plot(reg_med, pred = median_household_income, modx = unemployment )
# high unemployment
  int_1<-filter(crime, unemployment=="high") 
    reg_1<-lm(hate_crimes_per_100k_splc ~ median_household_income, data=int_1)
      broom::tidy(reg_1) #  not significant
# low unemployment
  int_2<-filter(crime, unemployment=="low") 
    reg_2<-lm(hate_crimes_per_100k_splc ~ median_household_income, data=int_2)
     broom::tidy(reg_2) # not significant


# Urbanization and median household income
reg_med_2<-lm(hate_crimes_per_100k_splc ~ median_household_income* urbanization, data = crime)
summary(reg_med_2)
interact_plot(reg_med_2, pred = median_household_income, modx = urbanization )
# high urbanization
  int_3<-filter(crime, urbanization=="high") 
    reg_3<-lm(hate_crimes_per_100k_splc ~ median_household_income, data=int_3)
      broom::tidy(reg_3) #  not significant
# low urbanization
  int_4<-filter(crime, urbanization=="low") 
    reg_4<-lm(hate_crimes_per_100k_splc ~ median_household_income, data=int_4)
     broom::tidy(reg_4) # not significant

# Urbanization and perc_population with HS degree
reg_per<-lm(hate_crimes_per_100k_splc ~ perc_population_with_high_school_degree* urbanization, data=crime)
  summary(reg_per)
    interact_plot(reg_per, pred = perc_population_with_high_school_degree, modx = urbanization )
# high urbanization
reg_5<-lm(hate_crimes_per_100k_splc ~ perc_population_with_high_school_degree, data=int_3)
  summary(reg_5) # significant!
# low urbanization
reg_6<-lm(hate_crimes_per_100k_splc ~ perc_population_with_high_school_degree, data=int_4)
  summary(reg_6) # not significant

# Median_household income and gini index
reg_gin<-lm(hate_crimes_per_100k_splc ~ median_household_income* gini_index, data=crime)
  summary(reg_gin)
    interact_plot(reg_gin, pred = median_household_income, modx = gini_index ) # not significant

```
There appears to be a significant interaction between urbanization and percent_pop with high school degree.


Check 3_way interactions between predictors of interest

```{r}

fit_4 = lm(hate_crimes_per_100k_splc ~ perc_population_with_high_school_degree *unemployment* gini_index, data = crime_trans)
summary(fit_4)
probe_interaction(fit_4, pred = perc_population_with_high_school_degree, modx = unemployment, mod2 = gini_index, alpha = .1)
```

Conclusion: There are no significant interactions between our predictors of interest

```{r}
# compare models
main = lm(hate_crimes_per_100k_splc~gini_index, data = crime_trans) ## Model with main predictor
broom::glance(main)

final_rec
broom::glance(final_rec) # our final recommended model
```

## everything below can be deleted



stepwise with all two-way interactions for full transformed data.
```{r}
trans_full_df = 
  crime_df %>% 
  mutate(
    hate_crimes_per_100k_splc = log(hate_crimes_per_100k_splc)
  )
```

```{r}
mod_trans_2way = lm(hate_crimes_per_100k_splc ~ (unemployment + perc_population_with_high_school_degree + gini_index)^2, data = trans_full_df)
step(mod_trans_2way, direction='backward')
```

stepwise with all three-way interactions for full transformed data.
```{r}
mod_trans_3way = lm(hate_crimes_per_100k_splc ~ (unemployment + perc_population_with_high_school_degree + gini_index)^3, data = trans_full_df)
step(mod_trans_3way, direction='backward')
```

stepwise with all two-way interactions for full non-transformed data.
```{r}
mod_2way = lm(hate_crimes_per_100k_splc ~ (unemployment + perc_population_with_high_school_degree + gini_index)^2, data = crime_df)
step(mod_2way, direction='backward')
```

stepwise with all three-way interactions for full non-transformed data.
```{r}
mod_3way = lm(hate_crimes_per_100k_splc ~ (unemployment + perc_population_with_high_school_degree + gini_index)^3, data = crime_df)
step(mod_3way, direction='backward')
```

